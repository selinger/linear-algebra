\section{Definition of vector spaces}
\label{sec:definition-vector-spaces}

\begin{outcome}
  \begin{enumerate}
  \item Develop the concept of a vector space through axioms.
  \item Use the vector space axioms to determine if a set and its
    operations constitute a vector space.
  \item Encounter several examples of vector spaces.
  \end{enumerate}
\end{outcome}

\begin{definition}{Vector space}{vector-space}
  Let $K$ be a field. A \textbf{vector space} over $K$%
  \index{vector space} is a set $V$ equipped with two operations of
  \textbf{addition}%
  \index{addition!in a vector space}%
  \index{vector!addition}%
  \index{addition!of vectors} and \textbf{scalar multiplication}%
  \index{scalar multiplication!in a vector space}%
  \index{vector!scalar multiplication}%
  \index{scalar multiplication!of a vector}%
  \index{multiplication!scalar multiplication|see{scalar multiplication}},
  such that the following properties hold:
  \begin{itemize}\setlength\itemsep{0em}
  \item[(A1)] Commutative law of addition%
    \index{commutative law!of addition}%
    \index{vector!commutative law of addition}:
    $\vect{u} + \vect{v}=\vect{v} + \vect{u}$.
  \item[(A2)] Associative law of addition%
    \index{associative law!of addition}%
    \index{vector!associative law of addition}:
    $(\vect{u} + \vect{v}) + \vect{w}=\vect{u} + (\vect{v} + \vect{w})$.
  \item[(A3)] The existence of an additive unit%
    \index{additive unit}%
    \index{unit!of addition|see{additive unit}}%
    \index{vector!additive unit}: there exists an element
    $\vect{0}\in V$ such that for all $\vect{u}$,
    $\vect{u} + \vect{0}=\vect{u}$.
  \item[(A4)] The law of additive inverses%
    \index{additive inverse}%
    \index{vector!additive inverse}%
    \index{inverse!additive}:
    $\vect{u} + (-\vect{u}) =\vect{0}$.
  \item[(SM1)] The distributive law over vector addition%
    \index{distributive law!over vector addition}%
    \index{vector!distributive law}:
    $k(\vect{u} + \vect{v}) = k\vect{u} + k\vect{v}$.
  \item[(SM2)] The distributive law over scalar addition%
    \index{distributive law!over scalar addition}:
    $(k + \ell) \vect{u} = k \vect{u} + \ell\vect{u}$.
  \item[(SM3)] The associative law for scalar multiplication%
    \index{associative law!of scalar multiplication}%
    \index{vector!associative law of scalar multiplication}:
    $k(\ell\vect{u}) = (k \ell)\vect{u}$.
  \item[(SM4)] The rule for multiplication by one%
    \index{rule for multiplication by 1}%
    \index{vector!rule for multiplication by 1}:
    $1\vect{u}=\vect{u}$.
  \end{itemize}
\end{definition}

The above definition is concerned about two operations: vector
addition, denoted by $\vect{v} + \vect{w}$, and scalar multiplication,
denoted by $k\vect{v}$ or sometimes $k\cdot\vect{v}$. In the law of
additive inverses, we have written $-\vect{u}$ for $(-1)\vect{u}$.
Often, the scalars will be real numbers, but it is also possible to
use scalars from a different field $K$. We also use the term
\textbf{$K$-vector space}%
\index{K-vector space@$K$-vector space} to refer to a vector space
over a field $K$.  When $K=\R$, we also speak of a \textbf{real vector
  space}%
\index{vector space!real}%
\index{real vector space}, and when $K=\C$, we speak of a
\textbf{complex vector space}%
\index{vector space!complex}%
\index{complex vector space}. If the field is clear from the context,
we often don't mention it at all, and just speak of a ``vector
space''. The elements of a vector space are called \textbf{vectors}%
\index{vector!in a vector space}.

Our first example of a vector space is of course $\R^n$.

\begin{example}{$\R^n$ is a vector space}{Rn-vector-space}
  The set $\R^n$ of $n$-dimensional real column vectors, with the
  usual operations of vector addition and scalar multiplication, is a
  vector space.

  More generally, if $K$ is a field, the set $K^n$ of $n$-dimensional
  column vectors with components in $K$ is a $K$-vector space.
\end{example}

\begin{proof}
  Properties (A1)--(A4) hold by
  Theorem~\ref{thm:properties-vector-addition}, and properties
  (SM1)--(SM4) hold by Theorem~\ref{thm:vector-scalar-multiplication}.
\end{proof}

We now consider some other examples of vector spaces.

\begin{example}{Vector space of polynomials of degree 2}{vector-space-polynomials2}
  Let $\Poly_2$%
  \index{P2@$\Poly_2$}%
  \index{vector space!of polynomials} be the set of all polynomials%
  \index{polynomial} of degree at most $2$ with coefficients from a
  field $K$, i.e., expressions of the form
  \begin{equation*}
    p(x) = ax^2 + bx + c,
  \end{equation*}
  where $a,b,c\in K$. Define addition%
  \index{polynomial!addition}%
  \index{addition!of polynomials} and scalar multiplication%
  \index{polynomial!scalar multiplication}%
  \index{scalar multiplication!of polynomials} of polynomials in the
  usual way, i.e.,
  \begin{eqnarray*}
    (ax^2 + bx + c) + (a'x^2 + b'x + c') &=& (a + a')x^2 + (b + b')x + (c + c') \\
    k(ax^2 + bx + c) &=& ka\,x^2 + kb\,x + kc.
  \end{eqnarray*}
  Then $\Poly_2$ is a vector space.
\end{example}

\begin{proof}
  To show that $\Poly_2$ is a vector space, we verify the $8$ vector
  space axioms. Let
  \begin{eqnarray*}
    p(x) &=& a_2x^2 + a_1x + a_0, \\
    q(x) &=& b_2x^2 + b_1x + b_0, \\
    r(x) &=& c_2x^2 + c_1x + c_0
  \end{eqnarray*}
  be polynomials in $\Poly_2$ and let $k,\ell$ be scalars.

  \begin{itemize}
  \item[(A1)] We prove the commutative law of addition.
    \begin{eqnarray*}
      p(x) + q(x)
      &=& (a_2x^2 + a_1x + a_0) + (b_2x^2 + b_1x + b_0) \\
      &=& (a_2 + b_2)x^2 + (a_1 + b_1)x + (a_0 + b_0) \\
      &=& (b_2 + a_2)x^2 + (b_1 + a_1)x + (b_0 + a_0) \\
      &=& (b_2x^2 + b_1x + b_0) + (a_2x^2 + a_1x + a_0) \\
      &=& q(x) + p(x).
    \end{eqnarray*}
  \item[(A2)] We prove the associative law of addition.
    \begin{eqnarray*}
      (p(x) + q(x)) + r(x)
      &=& ((a_2x^2 + a_1x + a_0) + (b_2x^2 + b_1x + b_0)) + (c_2x^2 + c_1x + c_0) \\
      &=& ((a_2 + b_2)x^2 + (a_1 + b_1)x + (a_0 + b_0)) + (c_2x^2 + c_1x + c_0) \\
      &=& ((a_2 + b_2) + c_2)x^2 + ((a_1 + b_1) + c_1)x + ((a_0 + b_0) + c_0) \\
      &=& (a_2 + (b_2 + c_2))x^2 + (a_1 + (b_1 + c_1))x + (a_0 + (b_0 + c_0)) \\
      &=& (a_2x^2 + a_1x + a_0) + ((b_2 + c_2)x^2 + (b_1 + c_1)x + (b_0 + c_0)) \\
      &=& (a_2x^2 + a_1x + a_0) + ((b_2x^2 + b_1x + b_0) + (c_2x^2 + c_1x + c_0)) \\
      &=& p(x) + (q(x) + r(x)).
    \end{eqnarray*}
  \item[(A3)] To prove the existence of an additive unit, let $0(x) =
    0x^2 + 0x + 0$, the so-called \textbf{zero polynomial}%
    \index{polynomial!zero}%
    \index{zero polynomial}. Then
    \begin{eqnarray*}
      p(x) + 0(x)  &=&  (a_2x^2 + a_1x + a_0) + (0x^2 + 0x + 0) \\
                   &=&  (a_2 + 0)x^2 + (a_1 + 0)x + (a_0 + 0) \\
                   &=&  a_2x^2 + a_1x + a_0 \\
                   &=&  p(x).
    \end{eqnarray*}
  \item[(A4)] We prove the law of additive inverses.
    \begin{eqnarray*}
      p(x) + (-p(x)) &=& (a_2x^2 + a_1x + a_0) + (- a_2x^2  - a_1x - a_0) \\
                     &=& (a_2 - a_2)x^2 + (a_1 - a_1)x + (a_0 - a_0) \\
                     &=& 0x^2 + 0x + 0 \\
                     &=& 0(x).
    \end{eqnarray*}
  \item[(SM1)] We prove the distributive law over vector addition.
    \begin{eqnarray*}
      k(p(x) + q(x)) &=& k ((a_2x^2 + a_1x + a_0) + (b_2x^2 + b_1x + b_0)) \\
                     &=& k ((a_2 + b_2)x^2 + (a_1 + b_1)x + (a_0 + b_0)) \\
                     &=& k(a_2 + b_2)x^2 + k(a_1 + b_1)x + k(a_0 + b_0) \\
                     &=& (ka_2 + kb_2)x^2 + (ka_1 + kb_1)x + (ka_0 + kb_0) \\
                     &=& (ka_2x^2 + ka_1x + ka_0) + (kb_2x^2 + kb_1x + kb_0) \\
                     &=& kp(x) + kq(x).
    \end{eqnarray*}
  \item[(SM2)] We prove the distributive law over scalar addition.
    \begin{eqnarray*}
      (k + \ell) p(x) &=& (k + \ell) (a_2x^2 + a_1x + a_0) \\
                 &=& (k + \ell)a_2x^2 + (k + \ell)a_1x + (k + \ell)a_0   \\
                 &=& (ka_2x^2 + ka_1x + ka_0) + (\ell a_2x^2 + \ell a_1x + \ell a_0) \\
                 &=& kp(x) + \ell p(x).
    \end{eqnarray*}
  \item[(SM3)] We prove the associative law for scalar multiplication.
    \begin{eqnarray*}
      k(\ell p(x)) &=& k(\ell(a_2x^2 + a_1x + a_0)) \\
               &=& k(\ell a_2x^2 + \ell a_1x + \ell a_0) \\
               &=&  k\ell a_2x^2 + k\ell a_1x + k\ell a_0 \\
               &=& (k\ell) (a_2x^2 + a_1x + a_0) \\
               &=& (k\ell) p(x).
    \end{eqnarray*}
  \item[(SM4)] Finally, we prove the rule for multiplication by one.
    \begin{eqnarray*}
      1p(x) &=& 1 (a_2x^2 + a_1x + a_0) \\
            &=& 1a_2x^2 + 1a_1x + 1a_0 \\
            &=& a_2x^2 + a_1x + a_0 \\
            &=& p(x).
    \end{eqnarray*}
  \end{itemize}
  Since the operations of addition and scalar multiplication on
  $\Poly_2$ satisfy the $8$ vector space axioms, $\Poly_2$ is a vector
  space.
\end{proof}

Our next example of a vector space is the set of all
$n\times m$-matrices.

\begin{example}{Vector space of matrices}{vector-space-matrices}
  Let $\Mat_{m,n}$%
  \index{Mmn@$\Mat_{m,n}$} be the set of all $m\times n$-matrices
  with entries in a field $K$%
  \index{vector space!of matrices}%
  \index{matrix!vector space of}, together with the usual operations
  of matrix addition and scalar multiplication. Then $\Mat_{m,n}$ is a
  vector space.
\end{example}

\begin{proof}
  The properties (A1)--(A4) hold by
  Theorem~\ref{thm:properties-of-addition}, and the properties
  (SM1)--(SM4) hold by Theorem~\ref{thm:properties-scalar-multiplication}.
\end{proof}

We now examine an example of a set that does not satisfy all of the
above axioms, and is therefore \textit{not} a vector space.

\begin{example}{Not a vector space}{not-vector-space}
  Let $V$ denote the set of $2 \times 3$-matrices. Let us define a
  non-standard addition in $V$ by $A \oplus B = A$ for all matrices
  $A,B\in V$. Let scalar multiplication in $V$ be the usual scalar
  multiplication of matrices. Show that $V$ is not a vector space.
\end{example}

\begin{solution}
  In order to show that $V$ is not a vector space, it suffices to find
  one of the 8 axioms that is not satisfied. We will begin by examining
  the axioms for addition until one is found which does not hold. In
  fact, for this example, the very first axiom fails. Let
  \begin{equation*}
    A = \begin{mymatrix}{rrr}
      1 & 0 & 0 \\
      0 & 0 & 0
    \end{mymatrix},
    \quad
    B = \begin{mymatrix}{rrr}
      0 & 0 & 0 \\
      1 & 0 & 0
    \end{mymatrix}.
  \end{equation*}
  Then $A\oplus B=A$ and $B\oplus A=B$. Since $A\neq B$, we have
  $A\oplus B\neq B\oplus A$ for these two matrices, so property (A1)
  is false.
\end{solution}

Our next example looks a little different.

\begin{example}{Vector space of functions}{vector-space-function}
  Let $X$ be a nonempty set, $K$ a field, and define $\Func_{X,K}$%
  \index{FuncXK@$\Func_{X,K}$} to be the set of functions
  \index{function!vector space of} defined on $X$ and valued in
  $K$. In other words, the elements of $\Func_{X,K}$ are functions
  $f:X\to K$. The sum of two functions is defined by
  \begin{equation*}
    (f + g)(x) = f(x) + g(x),
  \end{equation*}
  and the scalar multiplication is defined by
  \begin{equation*}
    (kf) (x) = k(f(x)).
  \end{equation*}
  Then $\Func_{X,K}$ is a vector space.
\end{example}

\begin{proof}
  To verify that $\Func_{X,K}$ is a vector space, we must prove the 8
  axioms of vector spaces. Let $f, g, h$ be functions in $\Func_{X,K}$,
  and let $k,\ell$ be scalars. Recall that two functions $f,g$
  are \textbf{equal}%
  \index{function!equality of}%
  \index{equality of functions} if for all $x\in X$, we have
  $f(x)=g(x)$.

  \begin{itemize}
  \item[(A1)] We prove the commutative law of addition. For all
    $x\in X$, we have
    \begin{equation*}
      (f + g) (x)
      ~=~ f(x) + g(x)
      ~=~ g(x) + f(x)
      ~=~ (g + f) (x).
    \end{equation*}
    Therefore, $f + g = g + f$.
  \item[(A2)] We prove the associative law of addition. For all
    $x\in X$, we have
    \begin{equation*}
      ((f + g) + h) (x)
      ~=~ (f + g) (x) + h(x)
      ~=~ (f(x) + g(x)) + h(x)
    \end{equation*}
    \begin{equation*}
      ~=~ f(x) + (g(x) + h(x))
      ~=~ (f(x) + (g + h) (x))
      ~=~ (f + (g + h)) (x).
    \end{equation*}
    Therefore, $(f + g) + h = f + (g + h)$.
  \item[(A3)] To prove the existence of an additive unit, let $0$
    denote the function that is given by $0(x)=0$. This is called the
    \textbf{zero function}%
    \index{function!zero function}%
    \index{zero function}. It is an additive unit because for all $x$,
    \begin{equation*}
      (f + 0) (x)
      ~=~ f(x) + 0(x)
      ~=~ f(x),
    \end{equation*}
    and so $f+0 = f$.
  \item[(A4)] We prove the law of additive inverses. Let $-f = (-1)f$
    be the function that satisfies $(-f) (x) = -f(x)$. Then for all $x$,
    \begin{equation*}
      (f + (-f)) (x)
      ~=~ f(x) + (-f) (x)
      ~=~ f(x) + -f(x)
      ~=~ 0.
    \end{equation*}
    Therefore $f + (-f) = 0$.
  \item[(SM1)] We prove the distributive law over vector addition. For
    all $x$, we have
    \begin{equation*}
      (k(f + g)) (x)
      ~=~ k(f + g) (x)
      ~=~ k(f(x) + g(x))
    \end{equation*}
    \begin{equation*}
      ~=~ kf(x) + k g(x)
      ~=~ (kf + kg) (x),
    \end{equation*}
    and so $k(f + g) = kf + kg$.
  \item[(SM2)] We prove the distributive law over scalar addition.
    \begin{equation*}
      ((k + \ell) f) (x)
      ~=~ (k + \ell) f(x)
      ~=~ kf(x) + \ell f(x)
      ~=~ (kf + \ell f) (x),
    \end{equation*}
    and so $(k + \ell) f = kf + \ell f$.
  \item[(SM3)] We prove the associative law for scalar multiplication.
    \begin{equation*}
      ((k\ell ) f) (x)
      ~=~ (k\ell) f(x)
      ~=~ k(\ell f(x))
      ~=~ (k(\ell f)) (x),
    \end{equation*}
    so $(k\ell f) =k(\ell f)$.
  \item[(SM4)] Finally, we prove the rule for multiplication by one.
    For all $x\in X$, we have
    \begin{equation*}
      (1f) ( x) ~=~ 1f(x) ~=~f(x),
    \end{equation*}
    and therefore $1f=f$.
  \end{itemize}

  It follows that $\Func_{X,K}$ satisfies all the required axioms and is a
  vector space.
\end{proof}

For the next two examples of vector spaces, we leave the proofs as an
exercise.

\begin{example}{Infinite sequences}{vector-space-sequences}
  Let $K$ be a field. A \textbf{sequence}%
  \index{sequence} of elements of $K$ is an infinite list
  \begin{equation*}
    (a_0,\,a_1,\,a_2,\,a_3\, \ldots),
  \end{equation*}
  where $a_i\in K$ for all $i$. We also use the notation
  $(a_i)_{i\in\N}$, or occasionally $(a_i)$, to denote such a
  sequence. Let $\Seq_K$ be the set of sequences%
  \index{vector space!of sequences}%
  \index{SeqK@$\Seq_K$} of elements of $K$. We add two
  sequences by adding their $i\th$ elements:
  \begin{equation*}
    (a_i)_{i\in\N} + (b_i)_{i\in\N} = (a_i+b_i)_{i\in\N}.
  \end{equation*}
  We scale a sequence by scaling each of its elements:
  \begin{equation*}
    k(a_i)_{i\in\N} = (ka_i)_{i\in\N}.
  \end{equation*}
  Then $\Seq_K$ is a vector space.
\end{example}

\begin{example}{Vector space of polynomials of unbounded degree}{vector-space-polynomials}
  Let $K$ be a field, and let $\Poly$%
  \index{P@$\Poly$}%
  \index{vector space!of polynomials} be the set of all polynomials%
  \index{polynomial} (of any degree) with coefficients from $K$, i.e.,
  expressions of the form
  \begin{equation*}
    p(x) = a_nx^n + a_{n-1}x^{n-1} + \ldots + a_1x + a_0,
  \end{equation*}
  where $n\geq 0$ and $a_0,\ldots,a_n\in K$. Addition and scalar
  multiplication of polynomials are defined in the usual way
  \index{polynomial!addition}%
  \index{addition!of polynomials}%
  \index{polynomial!scalar multiplication}%
  \index{scalar multiplication!of polynomials}.
  Then $\Poly$ is a vector space.
\end{example}

We conclude this section by deriving some initial consequences of the
vector space axioms.

\begin{proposition}{Elementary consequences of the vector space axioms}{vector-space-elementary}
  In any vector space, the following are true:
  \begin{enumialphparenastyle}
    \begin{enumerate}
    \item The additive unit is unique. In other words, whenever
      $\vect{u}+\vect{v}=\vect{u}$, then $\vect{v}=\vect{0}$.
    \item Additive inverses are unique. In other words, whenever
      $\vect{u}+\vect{v}=\vect{0}$, then $\vect{v}=-\vect{u}$.
    \item\label{vector-space-elementary-c} $0\vect{u}=\vect{0}$ for
      all vectors $\vect{u}$.
    \item The following \textbf{cancellation law}%
      \index{cancellation law!of addition}%
      \index{vector!cancellation law}
      holds: if $\vect{u} + \vect{w} = \vect{v} + \vect{w}$, then
      $\vect{u} = \vect{v}$.
    \end{enumerate}
  \end{enumialphparenastyle}
\end{proposition}

\begin{proof}
  We prove the first three properties, and leave the last one as an
  exercise. Assume $V$ is any vector space over a field $K$.
  \begin{enumialphparenastyle}
    \begin{enumerate}
    \item Consider arbitrary vectors $\vect{u},\vect{v}\in V$ and assume
      \begin{equation*}
        \vect{u}+\vect{v}=\vect{u}.
      \end{equation*}
      Applying the law (A1) (commutative law) to the left-hand side, we have
      \begin{equation*}
        \vect{v}+\vect{u}=\vect{u}.
      \end{equation*}
      Adding $-\vect{u}$ to both sides of the equation, we have
      \begin{equation*}
        (\vect{v}+\vect{u})+(-\vect{u}) = \vect{u}+(-\vect{u}).
      \end{equation*}
      Applying the law (A2) (associative law) to the left-hand side, we
      have
      \begin{equation*}
        \vect{v}+(\vect{u}+(-\vect{u})) = \vect{u}+(-\vect{u}).
      \end{equation*}
      Applying the law (A4) (additive inverse law) to both sides of the
      equation, we have
      \begin{equation*}
        \vect{v}+\vect{0} = \vect{0}.
      \end{equation*}
      Applying the law (A3) (additive unit law) to the left-hand side,
      we have
      \begin{equation*}
        \vect{v} = \vect{0}.
      \end{equation*}
      This proves that whenever $\vect{u}+\vect{v}=\vect{u}$, then
      $\vect{v} = \vect{0}$, or in other words, $\vect{v} = \vect{0}$ is
      the only element acting as an additive unit.

    \item Consider arbitrary vectors $\vect{u},\vect{v}\in V$ and assume
      \begin{equation*}
        \vect{u}+\vect{v}=\vect{0}.
      \end{equation*}
      Applying the law (A1) (commutative law) to the left-hand side, we
      have
      \begin{equation*}
        \vect{v}+\vect{u}=\vect{0}.
      \end{equation*}
      Adding $-\vect{u}$ to both sides of the equation, we have
      \begin{equation*}
        (\vect{v}+\vect{u})+(-\vect{u}) = \vect{0}+(-\vect{u}).
      \end{equation*}
      Applying the law (A2) (associative law) to the left-hand side, we
      have
      \begin{equation*}
        \vect{v}+(\vect{u}+(-\vect{u})) = \vect{0}+(-\vect{u}).
      \end{equation*}
      Applying the law (A4) (additive inverse law) to the left-hand
      side, we have
      \begin{equation*}
        \vect{v}+\vect{0} = \vect{0}+(-\vect{u}).
      \end{equation*}
      Applying the law (A1) (commutative law) to the right-hand side, we
      have
      \begin{equation*}
        \vect{v}+\vect{0} = -\vect{u} + \vect{0}.
      \end{equation*}
      Applying the law (A3) (additive unit law) to both sides of the
      equation, we have
      \begin{equation*}
        \vect{v} = -\vect{u}.
      \end{equation*}
      This proves that whenever $\vect{u}+\vect{v}=\vect{0}$, then
      $\vect{v} = -\vect{u}$, or in other words, $\vect{v} = -\vect{u}$
      is the only element acting as an additive inverse of $\vect{u}$.

    \item First, note that the scalar $0\in K$ satisfies the property
      $0+0=0$, by property (A3) of the definition of a field. Now let
      $\vect{u}\in V$ be any vector. Using the vector space law (SM2)
      (distributive law over scalar addition) and $0+0=0$, we have
      \begin{equation*}
        0\vect{u}+0\vect{u} = (0+0) \vect{u} = 0\vect{u}.
      \end{equation*}
      Next, we use a small trick: add $-(0\vect{u})$ to both sides of
      the equation. This gives
      \begin{eqnarray*}
        (0\vect{u}+0\vect{u})+(-(0\vect{u})) &=& 0\vect{u} + (-(0\vect{u})).
      \end{eqnarray*}
      Applying the additional laws (A2), (A4), and (A3), we have
      \begin{eqnarray*}
        0\vect{u}+(0\vect{u}+(-(0\vect{u}))) &=& 0\vect{u} + (-(0\vect{u})), \\
        0\vect{u} + \vect{0} &=& \vect{0}, \\
        0\vect{u} &=& \vect{0}.
      \end{eqnarray*}
      This proves that $0\vect{u} = \vect{0}$ holds for all vectors
      $\vect{u}$, as desired.

    \item This is left as an exercise.
    \end{enumerate}
  \end{enumialphparenastyle}
\end{proof}

