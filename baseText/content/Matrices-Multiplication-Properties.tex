\subsection{Properties of matrix multiplication}

We have already seen that matrix multiplication is not in general
commutative, i.e., $AB$ and $BA$ may be different, even if they are
both defined. Sometimes it can happen that $AB=BA$ for specific
matrices $A$ and $B$. In this case, we say that $A$ and $B$
\textbf{commute}%
\index{matrix!commuting matrices}%
\index{commuting matrices}.

The following are some properties of matrix multiplication.  Notice
that these properties hold only when the size of matrices are such
that the products are defined.

\begin{proposition}{Properties of matrix multiplication}{properties-of-matrix-multiplication}
  The following properties hold%
  \index{matrix!properties of multiplication}%
  \index{matrix!multiplication!properties}%
  \index{properties of multiplication!matrices} for matrices $A,B,C$
  of appropriate dimensions and for scalars $r$.
  \begin{itemize}
  \item The associative law of multiplication
    \begin{equation*}
      (AB)C ~=~ A(BC).
    \end{equation*}
  \item The existence of multiplicative units
    \begin{equation*}
      I_mA ~=~ A ~=~ AI_n,
    \end{equation*}
    where $A$ is an $m\times n$-matrix.
  \item Compatibility with scalar multiplication
    \begin{equation*}
      (rA)B ~=~ r(AB) ~=~ A(rB).
    \end{equation*}
  \item The distributive laws of multiplication over addition
    \begin{eqnarray*}
      A(B+C) &=& AB + AC, \\
      (B+C)A &=& BA + CA.
    \end{eqnarray*}
  \end{itemize}
\end{proposition}

\begin{proof}
  First, we will prove the associative law. In the proof, it will be
  useful to use {\em summation notation}%
  \index{summation notation}.  We write
  \begin{equation*}
    \sum_{i=1}^n x_i ~=~ x_1 + x_2 + \ldots + x_n
  \end{equation*}
  for the sum of the $n$ numbers $x_1,\ldots,x_n$. Assume $A$ is an
  $m\times n$-matrix, $B$ is an $n\times p$-matrix, and $C$ is a
  $p\times q$-matrix. Then both $(AB)C$ and $A(BC)$ are
  $m\times q$-matrices. We must show that they have the same
  entries. The $(i,\ell)$-entry of the matrix $(AB)C$ is
  \begin{equation*}
    ((AB)C)_{i\ell} = \sum_{k=1}^p (AB)_{ik}c_{k\ell}
    = \sum_{k=1}^p (\sum_{j=1}^n a_{ij}b_{jk})c_{k\ell}
    = \sum_{k=1}^p\sum_{j=1}^n a_{ij}b_{jk}c_{k\ell}.
  \end{equation*}
  On the other hand, the $(i,\ell)$-entry of the matrix $A(BC)$ is
  \begin{equation*}
    (A(BC))_{i\ell} = \sum_{j=1}^n a_{ij}(BC)_{j\ell}
    = \sum_{j=1}^n a_{ij} (\sum_{k=1}^p b_{jk} c_{k\ell})
    = \sum_{j=1}^n\sum_{k=1}^p a_{ij} b_{jk} c_{k\ell}.
  \end{equation*}
  Both sums are equal, since they are both summing over all the terms
  where $j=1,\ldots,n$ and $k=1,\ldots,p$. Therefore, $(AB)C=A(BC)$.
  The fact that identity matrices act as multiplicative units was
  already mentioned in Proposition~\ref{prop:identity-matrix}.  We
  leave compatibility with scalar multiplication as an exercise.
  To prove the first distributive law, assume $A$ is an
  $m\times n$-matrix, and $B$ and $C$ are $n\times p$-matrices. Then
  both $A(B+C)$ and $AB+AC$ are $m\times p$-matrices. We have
  \begin{equation*}
    (A(B+C))_{ik} = \sum_{j=1}^n a_{ij}(B+C)_{jk}
    = \sum_{j=1}^n a_{ij}(b_{jk}+c_{jk})
    = \sum_{j=1}^n a_{ij}b_{jk} + \sum_{j=1}^n a_{ij}c_{jk}
    = (AB+AC)_{ik}.
  \end{equation*}
  Thus $A(B+C) =AB+AC$ as claimed. The proof of the other distributive
  law is similar.
\end{proof}
